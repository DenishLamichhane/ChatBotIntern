{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7d29561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b16290",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Set your OpenAI API key\u001b[39;00m\n\u001b[0;32m     10\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-AIbBi48yxkbc3PrUwJvMT3BlbkFJYsQ8MXq2MtdMe85laJ8w\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.models'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "from langchain import OpenAI\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.models import Document\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Directory path where the text files are located\n",
    "directory_path = r\"C:\\Users\\user\\Desktop\\chatbot\"\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory_path, filename), \"r\") as file:\n",
    "                content = file.read()\n",
    "            document = Document(content)\n",
    "            documents.append(document)\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    with open('index.pkl', 'wb') as file:\n",
    "        pickle.dump(index, file)\n",
    "    return index\n",
    "\n",
    "def load_index_from_disk(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        index = pickle.load(file)\n",
    "    return index\n",
    "\n",
    "def collect_user_info():\n",
    "    print(\"Sure! Let's get started.\")\n",
    "    name = input(\"What's your name? \")\n",
    "    phone_number = input(\"What's your phone number? \")\n",
    "    email = input(\"What's your email? \")\n",
    "    if validate_input(name, phone_number, email):\n",
    "        call_user(name, phone_number, email)\n",
    "    else:\n",
    "        print(\"Please provide valid information.\")\n",
    "        collect_user_info()\n",
    "\n",
    "def validate_input(name, phone_number, email):\n",
    "    phone_regex = r\"^\\d{10}$\"\n",
    "    email_regex = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "    if not re.match(phone_regex, phone_number):\n",
    "        print(\"Invalid phone number format.\")\n",
    "        return False\n",
    "    elif not re.match(email_regex, email):\n",
    "        print(\"Invalid email format.\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def call_user(name, phone_number, email):\n",
    "    print(f\"Calling {name} at {phone_number}...\")\n",
    "    # Add your code to initiate a call using the provided information\n",
    "\n",
    "# Construct index (create index first)\n",
    "index = construct_index(directory_path)\n",
    "\n",
    "# Initialize Langchain\n",
    "langchain = OpenAI()\n",
    "\n",
    "# Function to ask AI\n",
    "def ask_ai(index):\n",
    "    while True:\n",
    "        query = input(\"What do you want to ask? \")\n",
    "        if query.lower() == \"call me\":\n",
    "            collect_user_info()  # Call this function if you want user info collection\n",
    "        else:\n",
    "            # Generate response using Langchain\n",
    "            response = langchain.query(query)\n",
    "            display(Markdown(f\"Response: <b>{response}</b>\"))\n",
    "\n",
    "# Now call the ask_ai function with the loaded index\n",
    "ask_ai(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d5b2bec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "nodes must be a list of Node objects.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 59\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mphone_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Add your code to initiate a call using the provided information\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Construct index (create index first)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m index \u001b[38;5;241m=\u001b[39m construct_index(directory_path)\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Initialize Langchain\u001b[39;00m\n\u001b[0;32m     62\u001b[0m langchain \u001b[38;5;241m=\u001b[39m OpenAI()\n",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m, in \u001b[0;36mconstruct_index\u001b[1;34m(directory_path)\u001b[0m\n\u001b[0;32m     19\u001b[0m             content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     20\u001b[0m         documents\u001b[38;5;241m.\u001b[39mappend(content)\n\u001b[1;32m---> 21\u001b[0m index \u001b[38;5;241m=\u001b[39m VectorStoreIndex(documents)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     23\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(index, file)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\core\\indices\\vector_store\\base.py:75\u001b[0m, in \u001b[0;36mVectorStoreIndex.__init__\u001b[1;34m(self, nodes, use_async, store_nodes_override, embed_model, insert_batch_size, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     69\u001b[0m     resolve_embed_model(embed_model, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embed_model\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m embed_model_from_settings_or_context(Settings, service_context)\n\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insert_batch_size \u001b[38;5;241m=\u001b[39m insert_batch_size\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     76\u001b[0m     nodes\u001b[38;5;241m=\u001b[39mnodes,\n\u001b[0;32m     77\u001b[0m     index_struct\u001b[38;5;241m=\u001b[39mindex_struct,\n\u001b[0;32m     78\u001b[0m     service_context\u001b[38;5;241m=\u001b[39mservice_context,\n\u001b[0;32m     79\u001b[0m     storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[0;32m     80\u001b[0m     show_progress\u001b[38;5;241m=\u001b[39mshow_progress,\n\u001b[0;32m     81\u001b[0m     objects\u001b[38;5;241m=\u001b[39mobjects,\n\u001b[0;32m     82\u001b[0m     callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[0;32m     83\u001b[0m     transformations\u001b[38;5;241m=\u001b[39mtransformations,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     85\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\llama_index\\core\\indices\\base.py:71\u001b[0m, in \u001b[0;36mBaseIndex.__init__\u001b[1;34m(self, nodes, objects, index_struct, storage_context, callback_manager, transformations, show_progress, service_context, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     66\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe constructor now takes in a list of Node objects. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSince you are passing in a list of Document objects, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease use `from_documents` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         )\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes must be a list of Node objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage_context \u001b[38;5;241m=\u001b[39m storage_context \u001b[38;5;129;01mor\u001b[39;00m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults()\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# deprecated\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: nodes must be a list of Node objects."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "from langchain import OpenAI\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "# Directory path where the text files are located\n",
    "directory_path = r\"C:\\Users\\user\\Desktop\\chatbot\"\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory_path, filename), \"r\") as file:\n",
    "                content = file.read()\n",
    "            documents.append(content)\n",
    "    index = VectorStoreIndex(documents)\n",
    "    with open('index.pkl', 'wb') as file:\n",
    "        pickle.dump(index, file)\n",
    "    return index\n",
    "\n",
    "def load_index_from_disk(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        index = pickle.load(file)\n",
    "    return index\n",
    "\n",
    "def collect_user_info():\n",
    "    print(\"Sure! Let's get started.\")\n",
    "    name = input(\"What's your name? \")\n",
    "    phone_number = input(\"What's your phone number? \")\n",
    "    email = input(\"What's your email? \")\n",
    "    if validate_input(name, phone_number, email):\n",
    "        call_user(name, phone_number, email)\n",
    "    else:\n",
    "        print(\"Please provide valid information.\")\n",
    "        collect_user_info()\n",
    "\n",
    "def validate_input(name, phone_number, email):\n",
    "    phone_regex = r\"^\\d{10}$\"\n",
    "    email_regex = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "    if not re.match(phone_regex, phone_number):\n",
    "        print(\"Invalid phone number format.\")\n",
    "        return False\n",
    "    elif not re.match(email_regex, email):\n",
    "        print(\"Invalid email format.\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def call_user(name, phone_number, email):\n",
    "    print(f\"Calling {name} at {phone_number}...\")\n",
    "    # Add your code to initiate a call using the provided information\n",
    "\n",
    "# Construct index (create index first)\n",
    "index = construct_index(directory_path)\n",
    "\n",
    "# Initialize Langchain\n",
    "langchain = OpenAI()\n",
    "\n",
    "# Function to ask AI\n",
    "def ask_ai(index):\n",
    "    while True:\n",
    "        query = input(\"What do you want to ask? \")\n",
    "        if query.lower() == \"call me\":\n",
    "            collect_user_info()  # Call this function if you want user info collection\n",
    "        else:\n",
    "            # Generate response using Langchain\n",
    "            response = langchain.query(query)\n",
    "            display(Markdown(f\"Response: <b>{response}</b>\"))\n",
    "\n",
    "# Now call the ask_ai function with the loaded index\n",
    "ask_ai(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8505c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Obtaining dependency information for google-generativeai from https://files.pythonhosted.org/packages/36/b7/5dbfe5703ace647e7250da9b9e746c4e9287eacfb5097cfa8fb2c15f1209/google_generativeai-0.4.1-py3-none-any.whl.metadata\n",
      "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai)\n",
      "  Obtaining dependency information for google-ai-generativelanguage==0.4.0 from https://files.pythonhosted.org/packages/40/c2/d28988d3cba74e712f47a498e2b3e3b58ac215106019bf5d8c20f8ab9822/google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata\n",
      "  Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting google-auth>=2.15.0 (from google-generativeai)\n",
      "  Obtaining dependency information for google-auth>=2.15.0 from https://files.pythonhosted.org/packages/92/94/35ba55b5011185ea1c995938e7851b25e6092f15658afa9263cd65a67dd4/google_auth-2.28.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.28.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Obtaining dependency information for google-api-core from https://files.pythonhosted.org/packages/0f/87/373ab788a4682adc1a6900e54d54c750b7bd4be456d75b8bf64eccc23ef9/google_api_core-2.17.1-py3-none-any.whl.metadata\n",
      "  Downloading google_api_core-2.17.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (1.10.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.9.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.4.0->google-generativeai)\n",
      "  Obtaining dependency information for proto-plus<2.0.0dev,>=1.22.3 from https://files.pythonhosted.org/packages/ad/41/7361075f3a31dcd05a6a38cfd807a6eecbfb6dbfe420d922cd400fc03ac1/proto_plus-1.23.0-py3-none-any.whl.metadata\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/fb/2b/a64c2d25a37aeb921fddb929111413049fc5f8b9a4c1aefaffaafe768d54/cachetools-5.3.3-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=2.15.0->google-generativeai)\n",
      "  Obtaining dependency information for rsa<5,>=3.1.4 from https://files.pythonhosted.org/packages/49/97/fa78e3d2f65c02c8e1268b9aba606569fe97f6c8f7c2d74394553347c145/rsa-4.9-py3-none-any.whl.metadata\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.63.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.62.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core->google-generativeai)\n",
      "  Obtaining dependency information for grpcio-status<2.0.dev0,>=1.33.2 from https://files.pythonhosted.org/packages/09/49/52e46bcea1c7b07b87982e4f7ea8657c8679f1591c4eafc75f84549939ae/grpcio_status-1.62.1-py3-none-any.whl.metadata\n",
      "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n",
      "Downloading google_generativeai-0.4.1-py3-none-any.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.4 kB ? eta -:--:--\n",
      "   -------- ------------------------------- 30.7/137.4 kB 1.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 30.7/137.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------- --------------------- 61.4/137.4 kB 465.5 kB/s eta 0:00:01\n",
      "   ----------------------- --------------- 81.9/137.4 kB 456.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 137.4/137.4 kB 580.5 kB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "   ---------------------------------------- 0.0/598.7 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 112.6/598.7 kB 3.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 133.1/598.7 kB 1.6 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 174.1/598.7 kB 1.5 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 245.8/598.7 kB 1.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 317.4/598.7 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 419.8/598.7 kB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 532.5/598.7 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  593.9/598.7 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 598.7/598.7 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.28.2-py2.py3-none-any.whl (186 kB)\n",
      "   ---------------------------------------- 0.0/186.9 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 61.4/186.9 kB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 143.4/186.9 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 186.9/186.9 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.17.1-py3-none-any.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.0 kB ? eta -:--:--\n",
      "   -------------------------- ------------- 92.2/137.0 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 137.0/137.0 kB 4.1 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 0.0/48.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 48.8/48.8 kB ? eta 0:00:00\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading grpcio_status-1.62.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: rsa, proto-plus, cachetools, grpcio-status, google-auth, google-api-core, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed cachetools-5.3.3 google-ai-generativelanguage-0.4.0 google-api-core-2.17.1 google-auth-2.28.2 google-generativeai-0.4.1 grpcio-status-1.62.1 proto-plus-1.23.0 rsa-4.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36c0bde9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Gemini' from 'gemini_client' (C:\\Users\\user\\Desktop\\chatbot\\gemini_client.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Markdown, display\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgemini_client\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Gemini\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Set your Gemini API key\u001b[39;00m\n\u001b[0;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGENIMI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAIzaSyCeNvtL6y2sMMOGgWazHtDOM1fSnQplyQA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Gemini' from 'gemini_client' (C:\\Users\\user\\Desktop\\chatbot\\gemini_client.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from IPython.display import Markdown, display\n",
    "from gemini_client import Gemini\n",
    "\n",
    "# Set your Gemini API key\n",
    "os.environ[\"GENIMI_API_KEY\"] = \"AIzaSyCeNvtL6y2sMMOGgWazHtDOM1fSnQplyQA\"\n",
    "\n",
    "# Directory path where the text files are located\n",
    "directory_path = r\"C:\\Users\\user\\Desktop\\chatbot\"\n",
    "\n",
    "def construct_index(directory_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory_path, filename), \"r\") as file:\n",
    "                content = file.read()\n",
    "            documents.append(content)\n",
    "    return documents\n",
    "\n",
    "def load_index_from_disk(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        index = pickle.load(file)\n",
    "    return index\n",
    "\n",
    "def collect_user_info():\n",
    "    print(\"Sure! Let's get started.\")\n",
    "    name = input(\"What's your name? \")\n",
    "    phone_number = input(\"What's your phone number? \")\n",
    "    email = input(\"What's your email? \")\n",
    "    if validate_input(name, phone_number, email):\n",
    "        call_user(name, phone_number, email)\n",
    "    else:\n",
    "        print(\"Please provide valid information.\")\n",
    "        collect_user_info()\n",
    "\n",
    "def validate_input(name, phone_number, email):\n",
    "    phone_regex = r\"^\\d{10}$\"\n",
    "    email_regex = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "    if not re.match(phone_regex, phone_number):\n",
    "        print(\"Invalid phone number format.\")\n",
    "        return False\n",
    "    elif not re.match(email_regex, email):\n",
    "        print(\"Invalid email format.\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def call_user(name, phone_number, email):\n",
    "    print(f\"Calling {name} at {phone_number}...\")\n",
    "    # Add your code to initiate a call using the provided information\n",
    "\n",
    "# Construct index (create index first)\n",
    "documents = construct_index(directory_path)\n",
    "\n",
    "# Initialize Gemini\n",
    "gemini = Gemini()\n",
    "\n",
    "# Function to ask Gemini\n",
    "def ask_gemini(documents):\n",
    "    while True:\n",
    "        query = input(\"What do you want to ask? \")\n",
    "        if query.lower() == \"call me\":\n",
    "            collect_user_info()  # Call this function if you want user info collection\n",
    "        else:\n",
    "            # Generate response using Gemini\n",
    "            response = gemini.generate_response(query, documents)\n",
    "            display(Markdown(f\"Response: <b>{response}</b>\"))\n",
    "\n",
    "# Now call the ask_gemini function with the loaded documents\n",
    "ask_gemini(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753c986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
